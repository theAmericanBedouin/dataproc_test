name: Dataproc Serverless Test

on:
  push:
    branches: [ "main" ]

jobs:
  job_id:
    runs-on: ubuntu-latest
    # Add "id-token" with the intended permissions.
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    # actions/checkout MUST come before auth
    - uses: 'actions/checkout@v3'
    - run: |
          pwd
          ls

    - id: 'auth'
      name: 'Authenticate to Google Cloud'
      uses: 'google-github-actions/auth@v0.8.1'
      with:
        workload_identity_provider: 'projects/203133753312/locations/global/workloadIdentityPools/dataproc-test/providers/github-actions' 
        service_account: 'github-actions-test@dataproc-test-365514.iam.gserviceaccount.com'

    - name: Set up gcloud Cloud SDK environment
      uses: google-github-actions/setup-gcloud@v0.6.0
    - run: |
        gcloud dataproc batches submit pyspark citibike.py \
          --batch=dataproc-citibike-job-gha \
          --region=us-central1 \
          --deps-bucket=dataproc-test-bucket-valdez \
          --jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.26.0.jar \
        --history-server-cluster=projects/dataproc-test-365514/regions/us-central1/clusters/my-phs \
          -- dataproc-test-bucket-valdez

    - name: 'Use gcloud CLI'
      run: 'gcloud info'
